# API Keys Configuration
# Comma-separated list of API keys that can access the gateway
API_KEYS=sk-your-key-1,sk-your-key-2

# API Key Permissions (optional)
# Use wildcards (*) to match multiple models
API_KEY_1_MODELS=gpt-4*,claude-3*,gemini-*
API_KEY_1_RATE_LIMIT=60/min

API_KEY_2_MODELS=*
API_KEY_2_RATE_LIMIT=100/min

# Default API Key (if API_KEYS is not set)
DEFAULT_API_KEY=default-key

# OpenAI Configuration
OPENAI_API_KEY=sk-...
# If MODELS is empty and BASE_URL is set, models will be auto-fetched from the provider
OPENAI_MODELS=gpt-4,gpt-4-turbo,gpt-3.5-turbo,dall-e-3
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_WEIGHT=1
OPENAI_ENABLED=true
OPENAI_TIMEOUT=120000

# Multiple OpenAI accounts
OPENAI_1_API_KEY=sk-...
OPENAI_1_MODELS=gpt-4,gpt-3.5-turbo
OPENAI_1_WEIGHT=2

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODELS=claude-3-opus,claude-3-sonnet,claude-3-haiku
ANTHROPIC_WEIGHT=1
ANTHROPIC_TIMEOUT=120000

# Google Gemini Configuration
GEMINI_API_KEY=...
GEMINI_MODELS=gemini-pro,gemini-pro-vision
GEMINI_WEIGHT=1

# Groq Configuration
GROQ_API_KEY=...
GROQ_MODELS=llama3-70b,mixtral-8x7b
GROQ_BASE_URL=https://api.groq.com/openai/v1
GROQ_WEIGHT=1

# OpenRouter Configuration
OPENROUTER_API_KEY=...
OPENROUTER_MODELS=*
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_WEIGHT=1

# 302.AI Configuration
302AI_API_KEY=...
302AI_MODELS=*
302AI_BASE_URL=https://api.302.ai/v1
302AI_WEIGHT=1

# xAI Configuration
XAI_API_KEY=...
XAI_MODELS=grok-*
XAI_BASE_URL=https://api.x.ai/v1
XAI_WEIGHT=1

# Cloudflare Workers AI Configuration
CLOUDFLARE_API_KEY=...
CLOUDFLARE_PROJECT_ID=your-account-id
CLOUDFLARE_MODELS=*
CLOUDFLARE_WEIGHT=1

# Azure OpenAI Configuration
AZURE_API_KEY=...
AZURE_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
AZURE_MODELS=gpt-4,gpt-35-turbo
AZURE_WEIGHT=1

# Cohere Configuration
COHERE_API_KEY=...
COHERE_MODELS=command,command-light
COHERE_WEIGHT=1

# AWS Bedrock Configuration
AWS_API_KEY=...
AWS_REGION=us-east-1
AWS_MODELS=anthropic.claude-*
AWS_WEIGHT=1

# Vertex AI Configuration
VERTEX_API_KEY=...
VERTEX_PROJECT_ID=your-project-id
VERTEX_REGION=us-central1
VERTEX_MODELS=gemini-pro,claude-*
VERTEX_WEIGHT=1

# Generic OpenAI-Compatible Providers
# Any provider that uses OpenAI-compatible API format can be configured with:
# {PROVIDER_NAME}_API_KEY and {PROVIDER_NAME}_BASE_URL
# 
# If MODELS is not specified, the system will auto-fetch available models
# 
# Examples:
CUSTOM_API_KEY=sk-...
CUSTOM_BASE_URL=https://your-openai-compatible-api.com/v1
CUSTOM_MODELS=model1,model2
CUSTOM_WEIGHT=1

ANOTHER_PROVIDER_API_KEY=sk-...
ANOTHER_PROVIDER_BASE_URL=https://another-compatible-api.com/v1
# If ANOTHER_PROVIDER_MODELS is not set, models will be auto-fetched

# Gateway Settings
DEFAULT_TIMEOUT=120000
MAX_RETRIES=3
COOLDOWN_TIME=300000
LOG_LEVEL=INFO

# Auto-fetch Models Feature
# If {PROVIDER}_MODELS is not set or empty, the system will automatically fetch 
# available models from the provider's API when {PROVIDER}_API_KEY and 
# {PROVIDER}_BASE_URL are configured. Supported providers:
# - OpenAI-compatible: openai, groq, openrouter, 302ai, xai, azure
# - Gemini: Uses Google's models API
# - Cohere: Uses Cohere's models API
# - Anthropic: Uses predefined model list (no API available)
# - Cloudflare: Requires CLOUDFLARE_PROJECT_ID

# Moderation Settings
MODERATION_ENABLED=true
OPENAI_MODERATION_API_KEY=sk-...

# Model-specific timeout (optional)
MODEL_GPT_4_TIMEOUT=180000
MODEL_CLAUDE_3_OPUS_TIMEOUT=150000
